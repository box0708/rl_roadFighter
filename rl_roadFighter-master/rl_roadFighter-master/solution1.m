
%% The same as defeintions in 'exercise1.m'.
% Generate the variables needed.
UP_LEFT = 1 ;
UP = 2 ;
UP_RIGHT = 3 ;

% PROBLEM SPECIFICATION:

blockSize = 5 ; 
n_MiniMapBlocksPerMap = 5 ; 
basisEpsisodeLength = blockSize - 1 ;

episodeLength = blockSize*n_MiniMapBlocksPerMap - 1 ;
%discountFactor_gamma = 1 ; % if needed
rewards = [ 1, -1, -20 ] ; 

probabilityOfUniformlyRandomDirectionTaken = 0.15 ;

roadBasisGridMaps = generateMiniMaps ; 

tempGrid = [ roadBasisGridMaps(2).Grid; ...
  roadBasisGridMaps(3).Grid; roadBasisGridMaps(2).Grid; ...
  roadBasisGridMaps(8).Grid; roadBasisGridMaps(7).Grid ] ;

tempStart = [ n_MiniMapBlocksPerMap * blockSize, 1 ] ;

tempMarkerRescaleFactor = 1/( (25^2)/36 ) ;

MDP_1 = GridMap(tempGrid, tempStart, tempMarkerRescaleFactor, ...
    probabilityOfUniformlyRandomDirectionTaken) ;

% Appending a matrix (same size size as the grid) with the locations of 
% cars:
MDP_1.CarLocations = [0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     1     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     1     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     1     0     0     0 ; ...
                      0     0     1     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     1     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     0     0     0 ; ...
                      0     0     1     0     0 ; ...
                      0     0     0     0     0 ];

MDP_1.RewardFunction = generateRewardFunction( MDP_1, rewards ) ;

%% Deterministic Policy to evaluate:
pi_test1 = UP * ones( MDP_1.GridSize ); % Default action: up.
pi_test1(:, 1) = UP_RIGHT; % When on the leftmost column, go up right.
pi_test1(:, 5) = UP_LEFT ; % When on the rightmost column, go up left.
pi_test1(:, 3) = UP_LEFT ; % When on the center column, go up left.

pi_test1_stateNumbers = zeros(1,125);
pi_test1_stateNumbers(:) = pi_test1';

%% Iterative Policy Evaluation

value_function = zeros(MDP_1.GridSize(1), MDP_1.GridSize(2) ); 
% initilize the value function (in this exercise, a 25*5 matrix)

value_function = policy_evaluation(MDP_1, value_function, pi_test1);

disp(value_function)








